# Human Pose Estimation using Machine Learning
This project is mainly focused on Human Pose Estimation using Machine Learning, which aims to identify the movements, position and pose of a human being. The primary objective is to identify and connect key human joints, such as elbows, knees, and shoulders, creating a visual representation of movement by drawing lines between them. 

 
The methodology uses a pre-trained deep learning model, like OpenPose or MediaPipe, to detect and extract the coordinates of key joints from each frame of a video. These joint points are then connected to create a skeleton overlay that visually represents the person’s posture and movements. The model analyzes the video frame by frame to ensure precise detection of joints and accurate tracking of movements throughout the video. This approach allows for a clear and detailed visual representation of how the body moves, making it easy to observe and study the person’s motion. 

 
Key results show the model's capacity to reliably recognize and map joints in a variety of positions and activities, including running. The technology gives real-time input, allowing users to precisely analyse their moves. The addition of elements such as joint angle computation and motion trajectory tracking increases the depth of analysis. 
